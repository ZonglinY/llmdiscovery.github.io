---
layout: about
title: Home
---

# LLMs for Scientific Discovery Workshop  @ ICML 2026
---
### <font color="#1e90ff">Date:</font> <font color="#333">July 10, 2026</font>
### <font color="#32cd32">Time:</font> 09:00-17:00
### <font color="#ff6347">Place:</font> COEX Convention & Exhibition Center, Seoul, South Korea
---

## Introduction
In recent years, the intersection of Artificial Intelligence and the natural sciences has undergone a fundamental paradigm shift. While traditional machine learning excelled at static property prediction, Large Language Models (LLMs) and Agentic AI have emerged as the driving force behind a new era of automated scientific discovery. This workshop emphasizes the methodological advancements—specifically in training strategies and inference-time reasoning—required to transform generic generative models into rigorous scientific agents.

By 2026, the role of AI in science has expanded to cover the full lifecycle of discovery. This workshop explores how agentic frameworks operate across distinct stages of the scientific process: from the Pre-experiment phase (where agents perform inspiration retrieval, knowledge recombination, and hypothesis generation) to the Experiment-guided phase (where agents utilize feedback loops, symbolic regression, and autonomous experimentation for iterative refinement). In these contexts, LLMs are no longer mere text processors but are evolving into reasoning engines capable of planning, symbolic decomposition, and self-correction. However, applying these probabilistic models to immutable scientific laws raises substantial challenges, necessitating novel approaches to bridge the gap between open-ended creativity and rigorous validity.

Key challenges and topics of interest include:
- **Inference-Time Reasoning & Search**: Techniques to enhance test-time compute for scientific problems (e.g., Tree of Thoughts, Monte Carlo Tree Search) to enable multi-step logical planning and complex experimental design.
- **Training & Alignment for Science**: Methodologies for Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) that align model outputs with physical constraints, mathematical logic, and experimental feedback.
- **Agentic Frameworks & Tool Use**: Architectures that support autonomous tool usage (simulators, code interpreters, lab equipment) and memory mechanisms for long-horizon scientific workflows.
- **Hypothesis Generation & Ranking**: Algorithms for generating novel, high-quality scientific hypotheses and ranking them based on plausibility, novelty, and verifiability.
- **Benchmarks & Evaluation**: Moving beyond rote memorization to evaluate true reasoning capabilities in out-of-distribution scientific discovery tasks.

This workshop aims to convene experts from machine learning, natural sciences, and automated reasoning to address these challenges. By focusing on the intersection of agentic workflows, advanced inference, and domain-specific training, the workshop seeks to foster collaboration and discussion on building reliable, interpretable AI systems. It will provide a platform for academics and industry professionals to exchange ideas on how to transition from "AI for Science" assistants to fully autonomous "AI Scientists," thereby enriching the discourse on AI's role in advancing human civilization.

## Program Committee Nominations

Call for Reviewers: If you are interested in contributing to our paper review process, please complete the [sign-up form](https://forms.gle/32dmEuJekgrhxzoW8). We will publicly acknowledge our program committee members. Your expertise and time dedicated to this effort are greatly appreciated and crucial to the success of the workshop.

## Submission Guideline

Please visit the [Call for papers](https://safegenaiworkshop.github.io/cfp) page for detailed guidelines.

## Invited Speakers
<div class="row projects pt-1 pb-1">
    <div class="col-sm-4">
      {% include people.html name="Chelsea Finn" affiliation="Stanford" url="https://ai.stanford.edu/~cbfinn/" img="assets/img/speakers/cf.jpg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Dawn Song" affiliation="UC Berkley" url="https://dawnsong.io/" img="assets/img/speakers/ds.jpg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Max Tegmark" affiliation="MIT" url="https://physics.mit.edu/faculty/max-tegmark/" img="assets/img/speakers/mt.jpg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Yoshua Bengio" affiliation="Mila, Université de Montréal" url="https://yoshuabengio.org/" img="assets/img/organizers/yb.jpg"%}
    </div>

</div>

## Organizers
<div class="row row-cols-2 projects pt-3 pb-3">
  {% include people_horizontal.html name="Dianbo Liu" affiliation="National University of Singapore" url="https://www.cogai4sci.com/" img="assets/img/organizers/dl.jpg" %}
  {% include people_horizontal.html name="Ling Pan" affiliation="Hong Kong University of Science and
Technology" url="https://ling-pan.github.io/" img="assets/img/organizers/lp.jpg" %}
  {% include people_horizontal.html name="Tailin Wu" affiliation="Westlake University" url="https://tailin.org/" img="assets/img/organizers/tw.jpg" %}
  {% include people_horizontal.html name="Emmanuel Bengio" affiliation="Recursion" url="https://folinoid.com/" img="assets/img/organizers/eb.jpg" %}
  {% include people_horizontal.html name="Yilun Du" affiliation="MIT" url="https://yilundu.github.io/" img="assets/img/organizers/yd.jpg" %}
  {% include people_horizontal.html name="Dinghuai Zhang" affiliation=" Microsoft Research" url="https://zdhnarsil.github.io/" img="assets/img/organizers/dz.jpg" %}
  {% include people_horizontal.html name="Bonaventure F. P. Dossou" affiliation="Mila, McGill University" url="https://bonaventuredossou.github.io/" img="assets/img/organizers/bd.jpg" %}
  {% include people_horizontal.html name="Yoshua Bengio" affiliation="Mila, Université de Montréal" url="https://yoshuabengio.org/" img="assets/img/organizers/yb.jpg" %}
  </div>

## Contact
If you have any questions, please contact us at [safe-generative-ai-workshop@googlegroups.com](mailto:safe-generative-ai-workshop@googlegroups.com).
